{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4d8e8ca",
   "metadata": {},
   "source": [
    "# Color-based Tracking\n",
    "moves away from tracking individual pixel gradients (like KLT) and instead focuses on tracking the **statistical distribution of colors** within a region. The two primary algorithms for this are **Mean Shift** and its improved version, **CamShift**.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Mean Shift Tracking\n",
    "\n",
    "Mean Shift is an iterative method for finding the \"peak\" or \"mode\" of a data distribution. In tracking, we use it to find the area in the current frame that most closely matches the **color histogram** of the object from the previous frame.\n",
    "\n",
    "#### How it works:\n",
    "\n",
    "1. **Define the Target:** You select a region (ROI) in the first frame.\n",
    "2. **Color Histogram:** You create a histogram of the target, typically in the **HSV color space** (Hue-Saturation-Value), because it is more robust to lighting changes than RGB.\n",
    "3. **Backprojection:** In the next frame, every pixel is replaced with its probability of belonging to that color histogram. This creates a \"probability map\" where the target looks like a bright blob.\n",
    "4. **The \"Shift\":** The algorithm starts a window at the last known position and calculates the **center of mass** of the probability map inside that window. It then moves (shifts) the window to that center.\n",
    "5. **Convergence:** This repeats until the window stops movingâ€”it has found the \"peak\" concentration of the target color.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. CamShift (Continuously Adaptive Mean Shift)\n",
    "\n",
    "The standard Mean Shift has one major problem: the size of the tracking window stays constant. If an object moves toward the camera (getting larger) or away (getting smaller), Mean Shift fails to adapt.\n",
    "\n",
    "**CamShift** solves this by:\n",
    "\n",
    "1. Running Mean Shift first to find the center.\n",
    "2. **Updating the window size:** It adjusts the window size based on the distribution of the color pixels.\n",
    "3. **Orientation:** It calculates the orientation of the object (e.g., if a person leans over), allowing the bounding box to rotate.\n",
    "\n",
    "---\n",
    "\n",
    "### Comparison: KLT vs. Mean Shift\n",
    "\n",
    "| Feature | KLT (Gradient-Based) | Mean Shift (Color-Based) |\n",
    "| --- | --- | --- |\n",
    "| **What is tracked?** | Specific corner points. | A distribution of colors. |\n",
    "| **Robustness** | High for rigid objects. | High for non-rigid objects (e.g., a shirt). |\n",
    "| **Failure Mode** | Fast motion or motion blur. | Similar colored backgrounds. |\n",
    "| **Input Requirement** | High-contrast textures. | Distinctive color patterns. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df07792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 1. Capture the initial frame and set the tracking window\n",
    "ret, frame = cap.read()\n",
    "# Define initial location of window: (x, y, width, height)\n",
    "x, y, w, h = 300, 200, 100, 100 \n",
    "track_window = (x, y, w, h)\n",
    "\n",
    "# 2. Set up the ROI for tracking\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Create a mask to ignore low light/low saturation pixels\n",
    "mask = cv2.inRange(hsv_roi, np.array((0., 60., 32.)), np.array((180., 255., 255.)))\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], mask, [180], [0, 180])\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# Setup the termination criteria: 10 iterations or move by at least 1pt\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # 3. Calculate Backprojection (Probability Map)\n",
    "    dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "\n",
    "    # 4. Apply Mean Shift to get the new location\n",
    "    ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "\n",
    "    # Draw it on image\n",
    "    x, y, w, h = track_window\n",
    "    img2 = cv2.rectangle(frame, (x, y), (x+w, y+h), 255, 2)\n",
    "    \n",
    "    cv2.imshow('MeanShift Tracking', img2)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
